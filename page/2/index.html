<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>cxf&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。">
<meta property="og:type" content="website">
<meta property="og:title" content="cxf&#39;s blog">
<meta property="og:url" content="http://treachery.github.io/page/2/index.html">
<meta property="og:site_name" content="cxf&#39;s blog">
<meta property="og:description" content="那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cxf&#39;s blog">
<meta name="twitter:description" content="那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。">
  
    <link rel="alternate" href="/atom.xml" title="cxf&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">cxf&#39;s blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">孤星独吟</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://treachery.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-管控中心/共享内存的回复" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/28/管控中心/共享内存的回复/" class="article-date">
  <time datetime="2017-09-28T01:28:55.000Z" itemprop="datePublished">2017-09-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/管控中心/">管控中心</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/28/管控中心/共享内存的回复/">内存问题排查</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="对于管控中心内存使用的调查"><a href="#对于管控中心内存使用的调查" class="headerlink" title="对于管控中心内存使用的调查"></a>对于管控中心内存使用的调查</h1><p>管控中心在新疆环境频繁出现内存使用量较高，然后超过阈值拒绝连接的情况。虽然在linux64位原则上我们是可以对内存不加限制的，但操作系统cgroup默认会有一些对进程资源的限制。况且我们的管控中心还要考虑windows32时使用的情况，所以内存的问题必须排除解决。目前看来，管控中心内存使用主要集中在几个点:pingcache，日志处理, 请求上报，请求回复</p>
<h2 id="pingcache"><a href="#pingcache" class="headerlink" title="pingcache"></a>pingcache</h2><p>使用虚拟的ip字符串，对一个B类段6万个ip，随机按照段连续上报(<strong><em>“192.168.0.1-192.168.10.255;192.168.11.1-192.168.20.255;192.168.21.1-192.168.100.255;192.168.101.1-192.168.255.255”</em></strong>),pingcache平均压测耗用内存200M左右。主要消耗内存或对象的点:</p>
<ol>
<li>上报的整个ip字符串，要每个ip拆分开进行过滤，过滤出来的对应的ip又要组合成字符串传给心跳处理函数<pre><code class="go">//将关键心跳过滤掉
func (this *deviceCache) FilterIp(iplist string) []string {
 arrips := strings.Split(iplist, &quot;;&quot;) //很消耗内存
 arrnewips := []string{}
 strids := &quot;&quot;
 for _, ip := range arrips {
     this.muxMapIpId.RLock()
     if id, ok := this.mapipid[ip]; ok { //设备心跳探测返回了,快速重置计数
         if len(strids) == 0 {
             strids += id
         } else {
             strids += &quot;,&quot; + id //非常消耗内存
         }
     } else { //不是心跳探测返回的设备，让其走正常的设备入库流程
         arrnewips = append(arrnewips, ip)
     }
     this.muxMapIpId.RUnlock()
 }
 this.multiSetPowerHeartBeat(strids)
 return arrnewips
}
</code></pre>
经过测试，使用string+连接字符串，无论执行速率还是内存使用都是最糟糕的，所以还是使用bytes.Buffer</li>
</ol>
<p><img src="stringBench.png" alt=""></p>
<ol>
<li>对应每个ip，pingcache内部有一个pingItemCache，包含一个定时器定时器对象，据说定时器对象很消耗cpu和GC，不过我没检查出来<pre><code class="go">type itemCache struct {
 clock *time.Timer
 res   int
 count int
}
</code></pre>
</li>
</ol>
<h2 id="日志处理"><a href="#日志处理" class="headerlink" title="日志处理"></a>日志处理</h2><p>目前看来还好，使用500个并发上报，每个上报10条短日志，整个请求加上入库处理，内存不超过100M。</p>
<h2 id="请求上报"><a href="#请求上报" class="headerlink" title="请求上报"></a>请求上报</h2><p>模拟500个并发0x6E交换机上报，每个连接上报32台设备，内存一分钟内上1G，主要分布如下,编码转换charsetconv以及字符串解析strnocasemap占据大头</p>
<p>占用 inuse_space<br><img src="request_inuse.png" alt=""></p>
<p>分配 alloc_space<br><img src="request_alloc.png" alt=""></p>
<h2 id="请求回复"><a href="#请求回复" class="headerlink" title="请求回复"></a>请求回复</h2><p>部分命令回复的数据量巨大，而且其实对每个客户端的同一请求，其实回复数据是一样的。对应新疆的情况，最大头就是保护列表。模拟环境下，500个客户端并发上报0x3保护列表，1分钟之内内存就飙升到1G。管控中心内存在这种情况的有下列三类，目前文件和保护列表暂时使用最大并发数做限制，阻断列表没限制</p>
<p>1 阻断列表</p>
<pre><code>a. 哨兵上报0x63 全部回复

b. 客户端上报0x5 回复部分
</code></pre><p>2 保护列表<br>    目前每次回复都是将保护列表文本复制一份到请求。</p>
<p>3 文件<br>    各个请求独立互斥地打开文件，读入套接字进行回复</p>
<h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><ol>
<li>对于连接数的限制</li>
</ol>
<p>linux下进程默认可打开的最大文件句柄数是1024，我们程序空载使用时打开了50个左右，主要是日志文件，各种动态链接库。目前限制虽然限制最大请求数是500，但经过压测h还是会从超出句柄限制的情况。原因如下，感觉我们还得降低最大连接数限制到900</p>
<p><img src="socket.png" alt=""></p>
<ol>
<li>内存回收</li>
</ol>
<pre><code class="go">// A MemStats records statistics about the memory allocator.
type MemStats struct {
    // General statistics.
    Alloc      uint64 // bytes allocated and not yet freed
    //当前进程占用着的内存
    TotalAlloc uint64 // bytes allocated (even if freed)
    //总的使用过的内存，已回收的也叠加
    Sys        uint64 // bytes obtained from system (sum of XxxSys below)
    //总的从操作系统请求的内存，可看做进程的内存峰值
    Lookups    uint64 // number of pointer lookups
    Mallocs    uint64 // number of mallocs
    Frees      uint64 // number of frees

    // Main allocation heap statistics.
    HeapAlloc    uint64 // bytes allocated and not yet freed (same as Alloc above)
    HeapSys      uint64 // bytes obtained from system
    HeapIdle     uint64 // bytes in idle spans
    HeapInuse    uint64 // bytes in non-idle span
    HeapReleased uint64 // bytes released to the OS
    HeapObjects  uint64 // total number of allocated objects
</code></pre>
<p>操作系统显示的RES与Alloc对比，多出来的应该应该是CGO申请的，未能被GC统计在内。对应管控中心应该主要是sqlite和数据库库驱动的内存。</p>
<ol>
<li><p>CGO的内存申请回收问题</p>
<p> 统计出来的应该是指针对象的数据内存占用</p>
<ol>
<li>代码</li>
</ol>
</li>
</ol>
<pre><code class="go">package main

/*
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
void CTest1(char* a1){
    printf(&quot;%p\n&quot;,a1);
}
void CTest2(char** a2){
    printf(&quot;%p\n&quot;,*a2);
}
*/
import &quot;C&quot;

import (
    &quot;log&quot;
    &quot;net/http&quot;
    _ &quot;net/http/pprof&quot;
    &quot;runtime&quot;
    &quot;runtime/debug&quot;
    &quot;time&quot;
    &quot;unsafe&quot;
)

func main() {

    go func() {
        http.ListenAndServe(&quot;:6060&quot;, nil)
    }()
    runtime.LockOSThread()
    for {
        test1()
        time.Sleep(time.Millisecond)
        runtime.GC()
        debug.FreeOSMemory()
    }
    runtime.UnlockOSThread()
}

var myval string = &quot;cqhujiohiiphjopohihiopj&quot;

func test1() {
    a1 := C.CString(myval)
    C.CTest1(a1)
    C.free(unsafe.Pointer(a1))

    a2 := C.CString(myval)
    C.CTest2(&amp;a2)
    C.free(unsafe.Pointer(a2))

    a3 := C.CString(myval)
    p3 := &amp;a3
    C.CTest2(p3)
    C.free(unsafe.Pointer(a3))

    a4 := C.CString(&quot;wyul;aleajkqojioiio&quot;)
    log.Printf(&quot;%p\n&quot;, a4)
    C.free(unsafe.Pointer(a4))

    C.CString(&quot;qdgyuhouohi&quot;)
}
</code></pre>
<pre><code>2. 对象
</code></pre><p><img src="objects.png" alt=""></p>
<pre><code>3. 内存
</code></pre><p><img src="memory.png" alt=""></p>
<p><img src="sysmemory.png" alt=""></p>
<ol>
<li>日志信息记录</li>
</ol>
<p>日志信息用于帮助我们在系统出问题时排查，正常情况下，如果系统高负载运转，日志应该可以不记录，但我们系统现在的问题是，高负载情况下虽然日志不接入文件了，但是依然有大量日志信息生成在内存内，反复申请和释放。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://treachery.github.io/2017/09/28/管控中心/共享内存的回复/" data-id="cjbqqt9u60000c8o0oleqn995" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/管控中心/">管控中心</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-golang相关/golang性能调优手册" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/28/golang相关/golang性能调优手册/" class="article-date">
  <time datetime="2017-09-28T01:10:25.000Z" itemprop="datePublished">2017-09-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/golang相关/">golang相关</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/28/golang相关/golang性能调优手册/">golang性能调优手册</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="golang性能调优"><a href="#golang性能调优" class="headerlink" title="golang性能调优"></a>golang性能调优</h1><h2 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h2><p>golang标准库附带了包runtime/pprof和/net/http/pprof用于程序的运行时监测。<br>帮助定位程序的cpu耗时，内存消耗回收，goroutine堆栈信息。另有tracers工具，可用于查看GC运行情况。</p>
<h2 id="CPU分析"><a href="#CPU分析" class="headerlink" title="CPU分析"></a>CPU分析</h2><h3 id="抓取数据"><a href="#抓取数据" class="headerlink" title="抓取数据"></a>抓取数据</h3><p>使用pprof工具有三种方法：</p>
<ol>
<li>导入test包的测试程序<br>直接使用go test -cpuprofile=cprof<br>将会生成文件cprof，使用go tool pprof cprof进行程序分析</li>
<li><p>导入runtime/pprof包<br>使用如下方法调用pprof的方法记录程序信息到文件中：</p>
<pre><code class="go">pprof.StartCPUProfile(f)
defer pprof.StopCPUProfile()
</code></pre>
</li>
<li><p>使用net/http/pprof包<br>对于持续运行的服务程序，这是最方便的方法。只需要导入net/http/pprof包并开启http监听，就能实时进行监控。例如添加<br>go func(){<br>http.ListenAndServe(“localhost:6060”,nil)<br>}()<br>访问<a href="http://localhost:6060:/debug/pprof可查看信息" target="_blank" rel="noopener">http://localhost:6060:/debug/pprof可查看信息</a></p>
</li>
</ol>
<h3 id="分析数据"><a href="#分析数据" class="headerlink" title="分析数据"></a>分析数据</h3><p>go tool pprof Manager.exe <a href="http://localhost:6060/debug/pprof/profile" target="_blank" rel="noopener">http://localhost:6060/debug/pprof/profile</a><br>等待一会儿，会生成一个程序运行的采样数据。pprof在程序中1s采样100次，根据采样的落点函数和执行代码，可分析各个函数占用cpu时间片的比例。</p>
<ol>
<li>top</li>
</ol>
<p>使用top查看耗时最多的函数：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>flat</td>
<td>采样点落在该函数累计时间</td>
</tr>
<tr>
<td>flat%</td>
<td>采样点落在该函数累计比例</td>
</tr>
<tr>
<td>sum%</td>
<td>前面比例的累计</td>
</tr>
<tr>
<td>cum</td>
<td>该函数加上被其调用的函数的采样点累计时间</td>
</tr>
<tr>
<td>cum%</td>
<td>该函数加上被其调用的函数的采样点累积百分比</td>
</tr>
</tbody>
</table>
<ul>
<li>list</li>
</ul>
<p>使用list 函数名 可以查看具体源码的采样时间</p>
<ul>
<li>web</li>
</ul>
<p>安装Cygwin，perl和Graphviz后，使用web命令可以直接生成一个各个函数模块的时间分配和调用图。每个box是一个function，根据function运行的采样数改变box的尺寸。从X到Y的一条边代表着X调用Y</p>
<ul>
<li>提示和建议</li>
</ul>
<p>提示：有三种特殊情形，pprof无法解开堆栈。GC，system和ExternalCode.</p>
<p>GC表示垃圾回收期间的用时</p>
<p>System表示goroutine调度程序，栈管理代码和其他辅助运行时代码的用时。</p>
<p>ExternalCode表示本地动态库的耗时</p>
<p>建议：<br>1.大量时间消耗在内存分配的函数，暗示该程序产生了大量的小内存分配工作。参考下面内存分析器部分的建议。</p>
<p>2.如果大量时间消耗在同步，互斥等待等，说明程序共享资源的访问有问题</p>
<p>3.如果大量时间消耗在系统调用读写，暗示程序产生大量的小块读写。可以考虑使用bufio来优化。</p>
<p>4.如果大量时间消耗在GC，说明程序分配了大量的临时对象，或者系统设置的堆栈空间太小，以至于GC频率过高。</p>
<h2 id="内存分析"><a href="#内存分析" class="headerlink" title="内存分析"></a>内存分析</h2><h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>类似cpu数据的获取<br>go test –memprofile<br>runtime/pprof.WriteHeapProfile<br><a href="http://localhost:6060:/debug/pprof/heap" target="_blank" rel="noopener">http://localhost:6060:/debug/pprof/heap</a></p>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>提示：内存分析器采取抽样，所以抓取出来的结果不一定精确表示分配的值，仅仅是一个按比例的描述。这个抽样可以通过设置配置Runtime.MemProfileRate调整。如果比例为1，则所以申请信息会被记录，但这样影响执行效率。默认采样比例为每分配512kb内存就采样一次。</p>
<pre><code class="shell">go tool pprof 参数  manager.exe http://localhost:6060:/debug/pprof/heap
</code></pre>
<p>常用的参数有：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>–inuse_space</td>
<td>当前时间内申请的空间</td>
</tr>
<tr>
<td>–alloc_space</td>
<td>自程序启动以来全部的请求空间</td>
</tr>
<tr>
<td>–inuse_objects</td>
<td>当前时间内申请的对象</td>
</tr>
<tr>
<td>–alloc_objects</td>
<td>自程序启动以来全部的对象申请</td>
</tr>
<tr>
<td>–functions</td>
<td>报告在函数等级</td>
</tr>
<tr>
<td>–lines</td>
<td>报告到代码行等级</td>
</tr>
<tr>
<td>–addresses/–files</td>
<td>精确到指令地址等级 或文件等级</td>
</tr>
</tbody>
</table>
<p>如果需要减少内存消耗量，需要关注–inuse_space的信息。如果需要提升程序运行效率，则要关注–alloc_objects</p>
<p>总体监控，查看与内存和对象分配相关所有堆栈信息<br>查看：<a href="http://localhost://6060/debug/pprof/heap?debug=1" target="_blank" rel="noopener">http://localhost://6060/debug/pprof/heap?debug=1</a></p>
<p>前面4个数字分别代表（1:28416 [1:28416]）<br>num1: 存活的该对象个数<br>num2: 存活对象占用的内存<br>num3: 所有该类型对象个数<br>num4: 所有该类型对象申请的内存</p>
<h3 id="优化建议"><a href="#优化建议" class="headerlink" title="优化建议"></a>优化建议</h3><p>堆区使用的优化根据不同应用场景有所区别，但有几个基本原则是通用的：</p>
<ul>
<li><p>尽量将小对象合并为大对象，减少对象数量使用。例如：将*bytes.Buffer替换为bytes。使用bytes.Buffer时，提前使用bytes.Grow将缓冲大小设置到合适值。既能减少内存分配，也减轻GC负担。</p>
</li>
<li><p>同样生命周期的临时变量，使用结构体将他们合并，也能减少对象个数.下方代码使用结构体，将两次内存分配缩减为1次。不过，这样的优化会影响代码可读性，所以见仁见智吧</p>
</li>
</ul>
<pre><code class="go">for k,v:=range m{
    k1,v1:=k,v
    go func(ktemp string,string){
        //使用两个对象
    }(k1,v1)
}

for k,v:=range m{
    k1,v1:=struct{k1,v1 string}{k,v}
    go func(ktemp interface{},vtemp interface{}){
        //使用一个对象
    }(k1,v1)
}
</code></pre>
<ul>
<li><p>对于大部分你已经预估到大小的切片,使用预分配的方式可以减少内存分配次数，例如：</p>
</li>
<li><p>尽量使用占内存小的数据类型。例如使用int8</p>
</li>
<li><p>不包含指针的对象(注意：strings,slices,maps,chans包含隐性指针)，GC回收时不需要进行扫描。所以，优化的方向是，尽量减少那些频繁使用的对象里面的指针。1是可以用索引替换指针。二是可以将对象拆分为两个，一个包含指针但是使用不频繁，另一个不包含指针使用频繁。</p>
</li>
<li><p>使用freelist减少临时对象的申请和分配。标准库sync.Pool可用于管理临时对象。不过不恰当地使用该功能，可能会产生资源提前释放的错误。<br>更多内存问题的查找，使用GC Trace</p>
</li>
</ul>
<h2 id="阻塞分析"><a href="#阻塞分析" class="headerlink" title="阻塞分析"></a>阻塞分析</h2><h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><pre><code class="shell">runtime/pprof.Lookup(&quot;block&quot;).WriteTo
</code></pre>
<p>go test –blockprofile<br><a href="http://localhost:6060/debug/pprof/block" target="_blank" rel="noopener">http://localhost:6060/debug/pprof/block</a></p>
<p>阻塞调试默认情况没有开启，使用runtime.SetBlockProfileRate(rate)开启阻塞调试。该函数参数rate指定采样的微秒数内，一个阻塞事件发生的平均数。设置rate=1,获取所有的阻塞。</p>
<h3 id="数据分析-1"><a href="#数据分析-1" class="headerlink" title="数据分析"></a>数据分析</h3><p>每个阻塞的描述信息：阻塞总时间(ns)，阻塞次数，调用栈<br>并非所有阻塞都是坏的，当一个routine阻塞时，调用线程会切换到另一个routine执行，所以阻塞是go语言这种cooperative语言实现并行的特殊方式。并不同于C++或者java里面发生的mutex阻塞（C++和JAVA的线程调度机制，阻塞直接导致线程空载和上下文切换)</p>
<p>阻塞的几种情况：</p>
<ul>
<li>goroutine由time.Ticker阻塞是正常的。</li>
<li>goroutine由sync.WaitGroup阻塞一般也是正常的。</li>
<li>goroutine由sync.Cond阻塞就可能有问题，要视具体情况而定，<br>消费者阻塞一般是生产者过慢或资源竞争。生产者阻塞一般是消费者过慢，不过大部分情况问题不大。</li>
<li>由chan信号引起阻塞，表面通道大小限制了goroutine数量</li>
<li>由锁引起的阻塞，一般就比较糟糕了，说明你的调度可能有问题。<br>（可以加参数–ignore，忽略不需要打印的阻塞种类。）</li>
</ul>
<p>阻塞两个副作用：</p>
<ul>
<li>多核CPU没有充分使用，程序线程集中跑在某个或某几个核上，一般由于任务划分不细，work太少。可以使用Scheduler Trace来追踪。</li>
<li>过多的goroutine阻塞或解除阻塞消耗CPU时间。使用CPU profiler来调试（观察 System component）</li>
</ul>
<h3 id="优化建议-1"><a href="#优化建议-1" class="headerlink" title="优化建议"></a>优化建议</h3><ul>
<li>在生产者消费者通道中，尽量使用足够大的带缓冲的chan。</li>
<li>对读取较多的共享资源，使用RWMutex读写锁，读锁不会阻塞其他读者线程。</li>
<li>使用写时拷贝(copy-on-write)处理一些修改不频繁的共享变量。类似如下的方法。去掉了mutex，使得写操作不会阻塞读线程。</li>
<li>拆分共享变量，只提取出需要加锁那部分进行锁定。可减少共享资源引起的阻塞。</li>
<li>本地缓存然后批处理更新有助于减少不可分割共享资源的访问冲突</li>
<li>使用sync.Pool代替基于chan-based或者mutex-protected的freelist。因为sync.Pool底层使用更高效的调度尽量避免了block。</li>
</ul>
<h2 id="goroutine-profile"><a href="#goroutine-profile" class="headerlink" title="goroutine profile"></a>goroutine profile</h2><p>goroutine Profiler给出当先存活的routine的调用栈，方便定位负载均衡和死锁。</p>
<p>最常用的是使用<a href="http://localhost:6060:/debug/pprof/goroutine?debug=2。这会给出类似程序崩溃时的详细栈信息。也可以在程序中使用runtime/pprof.Lookup(&quot;goroutine&quot;).WriteTo读取。" target="_blank" rel="noopener">http://localhost:6060:/debug/pprof/goroutine?debug=2。这会给出类似程序崩溃时的详细栈信息。也可以在程序中使用runtime/pprof.Lookup(&quot;goroutine&quot;).WriteTo读取。</a></p>
<p>注意：处于”syscalss”状态的routine消耗一个操作系统线程，其他的不会(除了直接调用runtime.LockOSThread，不过该调用对profile是不可见的)。其他的协程，即使是”IO Wait”都不消耗操作系统线程，他们使用非阻塞的网络轮询器实现。</p>
<h2 id="GC-Trace"><a href="#GC-Trace" class="headerlink" title="GC Trace"></a>GC Trace</h2><h3 id="gctrace"><a href="#gctrace" class="headerlink" title="gctrace"></a>gctrace</h3><p>在代码中关闭gc:<br>defer debug.SetGCPercent(debug.SetGCPercent(-1))<br>启用GC trace需要设置环境变量GODEBUG=gctrace=1<br>输出格式：</p>
<p>gc # @#s  #%: #+#+# ms clock, #+#/#/#+# ms cpu,#-&gt;#-&gt;#MB, # MB goal , # P</p>
<table>
<thead>
<tr>
<th>格式</th>
<th>解析</th>
</tr>
</thead>
<tbody>
<tr>
<td>gc #</td>
<td>GC次数编号</td>
</tr>
<tr>
<td>@#s</td>
<td>从程序开始的时间</td>
</tr>
<tr>
<td>#%</td>
<td>GC的时间占程序运行总时间的百分比</td>
</tr>
<tr>
<td>#+…+#</td>
<td>Wall-clock 和CPU time</td>
</tr>
<tr>
<td>#-&gt;#-&gt;#MB</td>
<td>堆大小 开始时-&gt;结束时-&gt;使用中</td>
</tr>
<tr>
<td># MB goal</td>
<td>触发下次强制GC需要达到的内存</td>
</tr>
<tr>
<td># P</td>
<td>运行的cpu核数</td>
</tr>
</tbody>
</table>
<p>wall-clock/CPU  times<br>(go语言的gc在1.4到1.5，1.5到1.7有较大改动，所以这个地方时间解释仅供1.5以下版本参考)</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>STW(stop the world) sweep termination</td>
<td>停止用户routine，启动清理</td>
</tr>
<tr>
<td>Concurrent mark and scan</td>
<td>堆扫描和标记时间，显著影响gc时间</td>
</tr>
<tr>
<td>STW mark termination</td>
<td>堆清理时间，通常与用户程序并行发生，影响不大</td>
</tr>
</tbody>
</table>
<p>关于垃圾回收的原理https：//lengzzz.com/note/gc-in-goang</p>
<p>一般2分钟发生一次强制GC。环境变量GOGC还可以设置下次发生GC的阈值，默认值100，表示的是当GO程序被分配了一块与当前内存相当大小的额外内存时，进行GC。<br>此外，GC是并行的，可以通过设置GOMAXPROCS来控制GC线程数量，不过数量有上限，go1.5是8</p>
<h3 id="allocfreetrace"><a href="#allocfreetrace" class="headerlink" title="allocfreetrace"></a>allocfreetrace</h3><p>设置环境变量GODEBUG=allocfreetrace=1<br>打印出内存分配的地址，大小，类型。以及分配内存的routine和分配栈。</p>
<h3 id="gotraceback"><a href="#gotraceback" class="headerlink" title="gotraceback"></a>gotraceback</h3><p>traceback用于在程序异常崩溃时，进行堆栈回溯记录，方便定位bug。</p>
<p>使用defer  recover记录error的堆栈<br>使用traceback记录panic的堆栈。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>GOTRACEBACK=none</td>
<td>只输出panic的信息</td>
</tr>
<tr>
<td>GOTRACEBACK=single</td>
<td>只输出被认为引发panic异常的那个goroutine的相关信息</td>
</tr>
<tr>
<td>GOTRACEBACK=all</td>
<td>输出所有用户级goroutines的相关信息，除去与go runtime相关的stack frames</td>
</tr>
<tr>
<td>GOTRACEBACK=system</td>
<td>输出所有goroutines的相关信息，包含系统级routine</td>
</tr>
<tr>
<td>GOTRACEBACK=crash</td>
<td>输出发生panic时所有堆栈信息，在linux系统上还能生成core文件</td>
</tr>
</tbody>
</table>
<h3 id="GC控制"><a href="#GC控制" class="headerlink" title="GC控制"></a>GC控制</h3><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>debug.SetGCPercent(percent  int)</td>
<td>用于控制强制GC的临界增量。默认percent=100，表示当go程序新申请一块与当前堆占用内存等量的内存时，会强制进行GC扫描。</td>
</tr>
<tr>
<td>runtime.GC()</td>
<td>强制执行GC，标记清扫不使用的内存</td>
</tr>
<tr>
<td>debug.FreeOSMemory()</td>
<td>强制执行scavenger，将被GC标记的不使用内存返还给操作系统。</td>
</tr>
</tbody>
</table>
<p>参考：</p>
<p><a href="https://github.com/golang/go/issues/4171" target="_blank" rel="noopener">https://github.com/golang/go/issues/4171</a><br><a href="https://github.com/golang/go/issues/16930" target="_blank" rel="noopener">https://github.com/golang/go/issues/16930</a></p>
<h2 id="辅助工具"><a href="#辅助工具" class="headerlink" title="辅助工具"></a>辅助工具</h2><h3 id="golint"><a href="#golint" class="headerlink" title="golint"></a>golint</h3><p>检查代码规范</p>
<h3 id="go-vet"><a href="#go-vet" class="headerlink" title="go vet"></a>go vet</h3><p>检查代码隐患</p>
<h3 id="race"><a href="#race" class="headerlink" title="-race"></a>-race</h3><p>检测竞争</p>
<h2 id="管控中心修改记录"><a href="#管控中心修改记录" class="headerlink" title="管控中心修改记录"></a>管控中心修改记录</h2><h3 id="worker-remotedebugger的内存泄露"><a href="#worker-remotedebugger的内存泄露" class="headerlink" title="worker_remotedebugger的内存泄露"></a>worker_remotedebugger的内存泄露</h3><p>该worker使用bytes.Buffer存储调试记录，当有调试连接上来时，运行日志要写入buffer，然后连接从该buffer中读取数据。然而由于buffer会随着调试日志增多而不断申请内存，而日志读取完后内存又不会释放。造成一定量内存浪费。</p>
<p>经检测，使用如下方式可以使多余的内存回收</p>
<pre><code class="go">this.outputBuffer = bytes.NewBuffer(make([]byte, 0, 1024))
//或者
this. outputBuffer=nil
/*前者重新初始化buffer，用于在缓冲区为空时，减少内存浪费
后者直接释放buffer，用于调试连接断开，不再需要往buffer写数据时使用
*/
</code></pre>
<h3 id="内存的强制回收"><a href="#内存的强制回收" class="headerlink" title="内存的强制回收"></a>内存的强制回收</h3><p>新建一个线程，在内存负载高时强制执行runtime.GC()和debug.FreeOSMemory()</p>
<h3 id="连接数控制，负载太高时，拒绝新连接"><a href="#连接数控制，负载太高时，拒绝新连接" class="headerlink" title="连接数控制，负载太高时，拒绝新连接"></a>连接数控制，负载太高时，拒绝新连接</h3><h3 id="日志入数据库慢的问题"><a href="#日志入数据库慢的问题" class="headerlink" title="日志入数据库慢的问题"></a>日志入数据库慢的问题</h3><ul>
<li><p>存储过程参数化执行，数据库驱动会去查询该过程的参数表，导致执行效率慢。</p>
<p>  解决办法，直接将参数拼接到sql字符串里面，使用无参数执行。</p>
</li>
<li><p>批量执行的两种参考方案 prepare 和事务</p>
</li>
</ul>
<h3 id="调试发现将日志解析为sql语句偏慢，大约1500条-s作用。使用profile发现适用于字符串处理过程中使用大量的string-replace。采用字符串拼接代替替换。"><a href="#调试发现将日志解析为sql语句偏慢，大约1500条-s作用。使用profile发现适用于字符串处理过程中使用大量的string-replace。采用字符串拼接代替替换。" class="headerlink" title="调试发现将日志解析为sql语句偏慢，大约1500条/s作用。使用profile发现适用于字符串处理过程中使用大量的string.replace。采用字符串拼接代替替换。"></a>调试发现将日志解析为sql语句偏慢，大约1500条/s作用。使用profile发现适用于字符串处理过程中使用大量的string.replace。采用字符串拼接代替替换。</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://treachery.github.io/2017/09/28/golang相关/golang性能调优手册/" data-id="cjbqqvffc0000z0o045r5d575" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang相关/">golang相关</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-管控中心/文件句柄数" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/07/21/管控中心/文件句柄数/" class="article-date">
  <time datetime="2017-07-21T01:01:10.000Z" itemprop="datePublished">2017-07-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/管控中心/">管控中心</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/07/21/管控中心/文件句柄数/">文件句柄数管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文件句柄数控制"><a href="#文件句柄数控制" class="headerlink" title="文件句柄数控制"></a>文件句柄数控制</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>我们现在的连接数控制逻辑有问题。在linux系统下，单进程默认打开的文件句柄数最大是1024，包含该进程打开的各种文件，动态静态链接库，套接字。管控中心现在打开各种日志文件，leveldb，sqlite，数据库，以及各种链接库，大概会占用几十个句柄。我们本来设计的默认逻辑是控制最大连接数为1000，但是我们其实是先用Accept创建了套接字，再去判断连接数的，这样其实没有起到控制连接数作用，请求高峰的时候，会出现套接字将句柄占满了，导致日志文件无法打开，出现too many open files 错误。</p>
<h2 id="修正点1-监听器的最大连接数"><a href="#修正点1-监听器的最大连接数" class="headerlink" title="修正点1:监听器的最大连接数"></a>修正点1:监听器的最大连接数</h2><p>对每个监听的最大连接数，可以使用netutil提供的LimitListener做限制</p>
<pre><code class="go">    //启动侦听
    for _, port := range this.arrPorts {
        gSyslogger.LogInfo(logger.LOGTP_INFO_NORMAL, fmt.Sprintf(&quot;TCP监听端口:%v&quot;, port))
        ln, err := net.Listen(&quot;tcp4&quot;, fmt.Sprintf(&quot;:%d&quot;, port))
        ln = netutil.LimitListener(ln, MaxConn)
        if err != nil {
            this.Stop()
            return fmt.Errorf(&quot;侦听TCP端口:%d 失败:%v&quot;, port, err)
        }
        this.arrListeners = append(this.arrListeners, ln)
        go this.startUDPListen(port)
    }
</code></pre>
<h2 id="修正点2-多种socket控制"><a href="#修正点2-多种socket控制" class="headerlink" title="修正点2:多种socket控制"></a>修正点2:多种socket控制</h2><p>我们需要控制多个端口，多种协议的总连接数。<br>主要有:<br>tcp166:<br>tcp2366:<br>udp166:<br>udp2366:<br>数据库连接<br>点对点下发请求(主要是设备替换命令0x70，agentfordebug查询命令)<br>htpp转发请求(交换机联动0x72,短信网关转发0x78，文件服务器更新?)</p>
<h2 id="修正点3-调试连接"><a href="#修正点3-调试连接" class="headerlink" title="修正点3:调试连接"></a>修正点3:调试连接</h2><p>对客户端的请求达到峰值的时候，其实我们还是希望调试请求能够连接上。默认管控中心开两个端口166和2366，其实一个达到峰值，accept不接收了，我们可以用另一个调试。但为了区分调试连接，我们得先区分协议头</p>
<h2 id="修正点4"><a href="#修正点4" class="headerlink" title="修正点4"></a>修正点4</h2><p>管它三七二十一，我们直接打包时修改系统的句柄数限制(<strong><strong>ulimit -n unlimited</strong></strong>)。这样除了请求连接数，其他都不去控制</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://treachery.github.io/2017/07/21/管控中心/文件句柄数/" data-id="cjbqqt9u60001c8o05h8mgx75" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/管控中心/">管控中心</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-管控中心/设备查找缓存" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/01/管控中心/设备查找缓存/" class="article-date">
  <time datetime="2017-04-01T01:33:34.000Z" itemprop="datePublished">2017-04-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/管控中心/">管控中心</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/04/01/管控中心/设备查找缓存/">设备查找缓存</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="修改记录"><a href="#修改记录" class="headerlink" title="修改记录"></a>修改记录</h1><h2 id="hashCache"><a href="#hashCache" class="headerlink" title="hashCache"></a>hashCache</h2><ol>
<li><p>设计逻辑<br>设备入库慢的最主要原因是设备在sqlite里面的查找慢，尤其涉及到partlike的逻辑时，基本是一个O(n)的复杂度，需要遍历整个设备表进行比对。</p>
</li>
<li><p>实现原理<br>在sqlite3里面对设备表Devices的ip和mac字段添加增删改触发器，触发器将ip，mac的变更以ip-&gt;idlist,mac-&gt;idlist存储到hash表。这样设备在查询时，先在hashCache查询到id，再去设备表按照id提取相应表值。</p>
</li>
<li><p>实现方法</p>
</li>
</ol>
<p>增删改触发器</p>
<pre><code>    //设备插入触发器
sqlTriggerInsert := `create TRIGGER DevicesInsert AFTER INSERT on Devices
    begin
        select ondeviceinsert(new.id,new.ip);
        select ondeviceinsert(new.id,new.mac);
    end;`

        _, err = this.pSqliteDB.Exec(sqlTriggerInsert)
        if err != nil {
            return err
        }
    //设备更新触发器
sqlTriggerUpdate := `create TRIGGER DevicesUpdate UPDATE OF ip,mac on Devices
    begin
        select ondevicedelete(new.id,old.ip);
        select ondevicedelete(new.id,old.mac);
        select ondeviceinsert(new.id,new.ip);
        select ondeviceinsert(new.id,new.mac);
    end;`

        _, err = this.pSqliteDB.Exec(sqlTriggerUpdate)
        if err != nil {
            return err
        }
    //设备删除触发器
sqlTriggerDelete := `create TRIGGER DevicesDelete AFTER DELETE on Devices
    begin
        select ondevicedelete(old.id,old.ip);
        select ondevicedelete(old.id,old.mac);
    end;`

        _, err = this.pSqliteDB.Exec(sqlTriggerDelete)
</code></pre><ol>
<li>增加触发器<br>在hashCache里面按照ip,mac为key找相应idlist，如果没有找到直接插入一条新的。<br>如果找到了，需要按照二分查找在相应位置把新的id做插入。<pre><code>func (dh *deviceHashCache) OnDeviceInsert(id int, ipmac string) int {
 //映射里面要全部拆分成单ip，单mac
 for _, one := range strings.Split(ipmac, &quot;;&quot;) { 
     if len(one) &gt; 0 {
         reslist := insert2sortedslice(id, dh.findidlist(one, false))
         dh.muxMapIPMacid.Lock()
         dh.mapIPMacidlist[one] = reslist
         dh.muxMapIPMacid.Unlock()
     }
 }
 return 1
}
</code></pre></li>
<li>删除触发器</li>
</ol>
<p>同理，按照ip，mac在hashCache里面查找，找到记录后按照二分查找法将对于id删除</p>
<pre><code>//OnDeviceDelete 设备删除触发器
func (dh *deviceHashCache) OnDeviceDelete(id int, ipmac string) int {
    dh.muxMapIPMacid.Lock()
    defer dh.muxMapIPMacid.Unlock()
    //映射里面要全部拆分成单ip，单mac
    for _, one := range strings.Split(ipmac, &quot;;&quot;) { 
        if len(one) &gt; 0 {
            if idlist, ok := dh.mapIPMacidlist[one]; ok {
                length := len(idlist)
                //只有一个，直接将key删除掉
                if length &lt;= 1 { 
                    delete(dh.mapIPMacidlist, one)
                } else { //有多个，将idlist替换掉
                    var newidlist []int
                    loc := binarySearch4find(idlist, id, 0, length-1)
                    if loc == 0 { //删头部
                        newidlist = idlist[1:]
                    } else if loc &gt; 0 {
                        newidlist = append(idlist[:loc-1], idlist[loc:]...)
                    }
                    if len(newidlist) &gt; 0 {
                        dh.mapIPMacidlist[one] = newidlist
                    }
                }
            }
        }
    }
    return 1
}
</code></pre><ol>
<li>修改触发器</li>
</ol>
<p>先调用删除触发器，再调用增加触发器</p>
<h2 id="扫描缓存队列"><a href="#扫描缓存队列" class="headerlink" title="扫描缓存队列"></a>扫描缓存队列</h2><p>1.设计逻辑<br>对同一条设备，由于扫描来源有多种，所以简单地FIFO队列会导致同一设备的不同属性需要分多次入库，加重了设备入库负担。(<strong><em>比如交换机采集上报了portid，portname等，类型识别上报OSdetail,HardwareCode,ping扫描上报了开机状态</em></strong>)，所以我们需要按照ip_mac为key的方法，将不同来源上报设备在缓存队列里面合并。</p>
<p>2.实现原理</p>
<ul>
<li>新设备上报上来，根据ip_mac在缓存队列生成一个item，3个key。key1=ip_mac,key2=ip,key3=mac(<strong><em>多ip，多mac设备就会有多个ip，mac的key。只有ip上报的设备就只有ipkey</em></strong>)</li>
<li>每条设备上报时的处理</li>
</ul>
<ol>
<li>如果同时有ip和mac，则以ip_mac为key在缓存hash表查找，找到item1后判断每个字段是否发生变更，如果有变更，则要将item1的序号发送到入库队列。 然后在按照ip为key查找，找到后将指针指向item1；再按照mac查找，找到后也将指针指向item1，并且要判断mac的指针是否发生变化，如果变化了，同样将item1的序号发送到入库队列</li>
<li><p>如果只有ip上报，则以ip为key查找，找到后判断item是否更新，更新了则加入到入库队列</p>
</li>
<li><p>入库队列取出一条item时，同时要更新扫描来源item.stype和item.Status</p>
</li>
</ol>
<p>3.实现方法</p>
<p>添加缓存项</p>
<pre><code>func (this *scanResultManager) addCache(ip string, mac string, item tagCommonItem) {
    this.arrResultCache = append(this.arrResultCache, item)
    id := len(this.arrResultCache) - 1
    if !common.IsEmpty_MAC(mac) {
        this.mapResultCache[ip+&quot;_&quot;+mac] = id
        this.mapResultCache[mac] = id
    }
    this.mapResultCache[ip] = id
    this.addtochan(id)
}
</code></pre><p>修改缓存项</p>
<pre><code>func (this *scanResultManager) modifyCache(inx int, ip, mac string, item tagCommonItem) {
    muxItem.Lock()
    defer muxItem.Unlock()
    if len(this.arrResultCache) &lt;= inx {
        return
    }
    olditem := this.arrResultCache[inx]
    if !strings.Contains(olditem.Stype, item.Stype) { //添加扫描类型
        olditem.Stype += &quot;;&quot; + item.Stype
    }
    //用新值覆盖旧值
    newElem := reflect.ValueOf(&amp;item).Elem()
    oldElems := reflect.ValueOf(&amp;olditem).Elem()
    /*
        stype，ip，mac三个值不在此更新
    */
    for i := 3; i &lt; oldElems.NumField(); i++ {
        mField := oldElems.Field(i)
        if !mField.CanSet() {
            continue
        }
        if mField.Kind() == reflect.Int {
            newvalue := newElem.Field(i).Int()
            if newvalue != 0 &amp;&amp; newvalue != mField.Int() {
                mField.SetInt(newvalue)
                this.addtochan(inx)
                olditem.UpdateState = 0
            }
        }
        if mField.Kind() == reflect.String {
            newvalue := newElem.Field(i).String()
            if newvalue != &quot;&quot; &amp;&amp; newvalue != mField.String() {
                mField.SetString(newvalue)
                this.addtochan(inx)
                olditem.UpdateState = 0
            }
        }
    }

    //是否发生ip替换，mac指针抢占
    if oldinx, ok := this.mapResultCache[mac]; ok &amp;&amp; oldinx != inx {
        this.addtochan(inx)
    }
    this.arrResultCache[inx] = olditem
}
</code></pre><p>查找设置缓存</p>
<pre><code>func (this *scanResultManager) seachAndSetCache(ip string, mac string, item tagCommonItem) {
    this.muxmapResultCache.Lock()
    defer this.muxmapResultCache.Unlock()
    find := false
    inx := -1
    key := &quot;&quot;
    if common.IsEmpty_MAC(mac) {
        key = ip
    } else {
        key = ip + &quot;_&quot; + mac
    }

    if inx, find = this.mapResultCache[key]; find { //ip和mac都匹配了
        goto SETCACHE
    }
SETCACHE:
    if find &amp;&amp; inx &gt;= 0 { //找到了进行补全
        this.modifyCache(inx, ip, mac, item)
    } else { //不匹配，添加一条
        this.addCache(ip, mac, item)
    }
}
</code></pre><h2 id="开关机缓存"><a href="#开关机缓存" class="headerlink" title="开关机缓存"></a>开关机缓存</h2><ol>
<li><p>设计逻辑<br>对于已经入库到设备表的ip，管控中心为了维护其开关机状态，需要定期使用ping扫描扫这些ip(<strong><em>关机心跳扫描每3分钟一次，开机扫描每12分钟一次</em></strong>)，这会导致大量ping上来的设备堆积到扫描入库缓存，并且某些设备既然已经堆积了，就没必要去ping它。</p>
</li>
<li><p>实现原理</p>
</li>
</ol>
<ul>
<li>关机心跳扫描每一轮时，把待ping设备ip,id取出来，将那些ip不重复的单ip设备加入到一个hash表，存储为map(ip-&gt;id)(<strong><em>多ip设备，或者ip有重复的设备还是要走扫描缓存队列，因为有些逻辑要判断</em></strong>)。ping扫描回复一批扫描结果时，将结果在map(ip-&gt;id)里面过滤，如果在hash表里面的，将其取出来，直接按id更新该设备的心跳周期和更新时间。剩下的再加入到扫描缓存队列。</li>
<li>开机扫描取设备ip时，将ip在入库缓存队列里面过滤，如果该ip已经在入库缓存队列等待设备开机了，就取出这个ip，不需要ping它了。</li>
</ul>
<ol>
<li>实现方法</li>
</ol>
<p>关机心跳探测</p>
<pre><code>func (this *deviceCache) pingDevice() {
    this.resetipmap()
    iplist := []string{}
    sqlite_getipip := &quot;select id,ip,count(*) as c from devices where sysPowerOffTestCount&gt;0 group by ip&quot; //单ip并且不和其他设备重复的，记录下id来，直接进行状态更新
    _, tb, err := this.Query(sqlite_getipip)
    if err != nil {
        return
    }
    for _, rows := range tb {
        count, _ := strconv.Atoi(rows[2])
        if count &lt;= 0 {
            continue
        }
        iplist = append(iplist, rows[1])
        if !strings.Contains(rows[1], &quot;;&quot;) &amp;&amp; count == 1 { //将id记录下来，用于快速更新
            this.addtoipmap(rows[1], rows[0])
        }
    }
    if len(iplist) &gt; 0 {
        face.GetPingServer().AddtoPingList(strings.Join(iplist, &quot;;&quot;))
    }
}
</code></pre><p>ping回复ip列表过滤</p>
<pre><code>func (this *deviceCache) FilterIp(iplist string) []string {
    arrips := strings.Split(iplist, &quot;;&quot;)
    arrnewips := []string{}
    strids := &quot;&quot;
    for _, ip := range arrips {
        this.muxMapIpId.RLock()
        if id, ok := this.mapipid[ip]; ok { //设备心跳探测返回了,快速重置计数
            if len(strids) == 0 {
                strids += id
            } else {
                strids += &quot;,&quot; + id
            }
        } else { //不是心跳探测返回的设备，让其走正常的设备入库流程
            arrnewips = append(arrnewips, ip)
        }
        this.muxMapIpId.RUnlock()
    }
    this.multiSetPowerHeartBeat(strids)
    return arrnewips
}
</code></pre><p>开机探测</p>
<pre><code>if count%SECOND_CHECK_HEART_BEAT*4 == 0 {
    _, tab, _ := gDeviceCache.Query(&quot;select ip from devices where devicestatus&amp;1!=1&quot;)
    tmpiplist := bytes.NewBuffer(nil)
    //需要进行开机探测设备太多,怕探不过来状态不准确,加长心跳延时
    if len(tab) &gt; 1000 { 
                this.calculatePingSec(len(tab))
    }
    for _, row := range tab {
        ip := row[0]
        //该ip有开机探测还没入库，直接跳过
        if gScanManager.TestIpInCache(ip) { 
            continue
        }
        if tmpiplist.Len() == 0 {
            tmpiplist.WriteString(ip)
        } else {
            tmpiplist.WriteString(&quot;;&quot; + ip)
        }
    }

    if common.GetCrc(tmpiplist.String()) != this.devcrc {
        this.devcrc = common.GetCrc(tmpiplist.String())
        this.pingCore.SetDevices(tmpiplist.String())
    }
}
</code></pre><h2 id="PING扫描"><a href="#PING扫描" class="headerlink" title="PING扫描"></a>PING扫描</h2><ol>
<li>设计逻辑<br>之前版本是多线程（<strong><em>goroutines</em></strong>）发送，即同时取一批设备(<strong><em>256个</em></strong>)，然后开256个线程将其发送出去，这样的好处是比较灵活，我们可以记录每个ip发送的icmp序列号，在接收端做校验，也可以在每个线程做定时器，记录每个ip的发送和接收间隔时间。但是在设备数量比较大的情况下，比如我们需要维护20000设备的开关机，那么每一轮(<strong><em>10s</em></strong>)至少需要进行1000个ip的发送和接收(<strong><em>排除掉重复发送和其他出来延时，这已经是最低要求</em></strong>)。在cpu空闲的时候还好，在cpu比较繁忙时(<strong><em>被资产识别组件，交换机采集组件，数据库占用</em></strong>)，就可能出现线程调度不到，出现大量发送超时。<br>修改版本使用单线程发送，单线程接收(C++版本现在也是这样的逻辑)，一次性读取足够数量ip（<strong><em>现在默认10000个，不够10000就读万</em></strong>），将其全部加入icmp发送缓存。接收端不做序列号验证，也不做超时判断，只要接收到的ip，就全部作为ping通的设备回调给扫描缓存。</li>
</ol>
<h2 id="其他改动"><a href="#其他改动" class="headerlink" title="其他改动"></a>其他改动</h2><ol>
<li>数据库驱动替换 commdb-&gt;commdb2(<strong><em>自动数据库驱动以及策略加解密的动态链接库</em></strong>)，对数据库连接池做了些设置</li>
<li>编译使用golang1.8，之前测试发现golang1.8对比golang1.7,在sqlite3性能测试时大概有10%-20%提升</li>
<li></li>
</ol>
<h2 id="功能添加"><a href="#功能添加" class="headerlink" title="功能添加"></a>功能添加</h2><ol>
<li>CMDToDBXMl添加(<strong><em>暂时没用到的功能</em></strong>)</li>
<li>准入系统添加了几个功能（安全登录身份认证，安全检查上报0x41）</li>
<li>主机监控系统添加了些日志(cpu，内存告警等等)</li>
<li>检查系统添加了些日志</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://treachery.github.io/2017/04/01/管控中心/设备查找缓存/" data-id="cjbqqt9ul0008c8o0ijn14tvh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/管控中心/">管控中心</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Hexo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/11/Hexo/" class="article-date">
  <time datetime="2016-07-11T02:24:08.000Z" itemprop="datePublished">2016-07-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/博客栈/">博客栈</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/11/Hexo/">快速搭建Hexo</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这篇文章主要是提醒自己半年更一次博客忘了要怎么做。当然如果想<strong>迅速</strong>建站，可是可以参考的。</p>
        
          <p class="article-more-link">
            <a href="/2016/07/11/Hexo/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://treachery.github.io/2016/07/11/Hexo/" data-id="cjbqle335000220o0875ypt2f" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/博客/">博客</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; 上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/golang/">golang</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/golang相关/">golang相关</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客栈/">博客栈</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/简历/">简历</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/管控中心/">管控中心</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang相关/">golang相关</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leaf/">leaf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/博客/">博客</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/简历/">简历</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/管控中心/">管控中心</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/golang相关/" style="font-size: 13.33px;">golang相关</a> <a href="/tags/leaf/" style="font-size: 16.67px;">leaf</a> <a href="/tags/博客/" style="font-size: 10px;">博客</a> <a href="/tags/简历/" style="font-size: 10px;">简历</a> <a href="/tags/管控中心/" style="font-size: 20px;">管控中心</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/12/28/个人简历/">个人简历</a>
          </li>
        
          <li>
            <a href="/2017/11/24/golang相关/GOadvices/">GOadvices</a>
          </li>
        
          <li>
            <a href="/2017/11/15/管控中心/文件中转服务改进/">文件中转服务改进</a>
          </li>
        
          <li>
            <a href="/2017/11/02/管控中心/管控中心文件中转服务/">文件中转服务逻辑</a>
          </li>
        
          <li>
            <a href="/2017/10/13/管控中心/管控中心数据库连接池管理/">数据库连接池管理</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 treachery<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>